"0","#cut the variable that doesnt improve the model"
"0","tresh<-10^(-3) # treschold to reduce select the columns to be used in the next iteration"
"0","dta_use<-dta_boos[,xgb_importance$Feature[xgb_importance$Gain>tresh]]"
"0","#str(dta_use)"
"0",""
"0","#find the best paramters"
"0","best_paramers<-Bosst_validation(max_depth_options,dta_use)"
"1","Trying maximum depth of"
"1"," "
"1","3"
"1"," "
"1","...
"
"1","Trying maximum depth of"
"1"," "
"1","4"
"1"," "
"1","...
"
"1","Trying maximum depth of"
"1"," "
"1","5"
"1"," "
"1","...
"
"1","Trying maximum depth of"
"1"," "
"1","6"
"1"," "
"1","...
"
"1","Hyperparameter selection: best nrounds is"
"1"," "
"1","78"
"1"," "
"1","and best maximum depth is"
"1"," "
"1","4"
"1"," "
"1","
"
"0","best_md<-best_paramers[1]"
"0","best_nrounds<-best_paramers[2]"
"0",""
"0","# train the final model and test"
"0","xgb_opt2 <- xgboost(data = as.matrix(data_used[train_points, ]), "
"0","                          label = dta$UNITS[train_points], "
"0","                          nrounds = best_nrounds, max_depth = best_md, verbose = FALSE)"
"0","xgb_opt_pred <- predict(xgb_opt2, as.matrix(data_used[-train_points,]))"
"0","cat(""Mean absolute error for optimised XGB:"","
"0","    mean(abs(xgb_opt_pred - dta$UNITS[-train_points])), ""\n"")"
"1","Mean absolute error for optimised XGB:"
"1"," "
"1","4.676641"
"1"," "
"1","
"
"0","#Save the test set"
"0",""
"0","MSE[7]<-mean(abs(xgb_opt_pred - dta$UNITS[-train_points]))"
"0","RMSE[7]<-(mean((xgb_opt_pred - dta$UNITS[-train_points])^2))^(1/2)"
"0","Row_name[7]<-paste(""xgb-"",ncol(dta_use),""vars (parms:"",best_nrounds,""-"",best_md,"")"")"
